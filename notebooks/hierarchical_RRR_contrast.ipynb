{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34c99679-0bcd-45fa-a454-6079471ea357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yizi/anaconda3/envs/clusterless/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/yizi/anaconda3/envs/clusterless/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c106detail19maybe_wrap_dim_slowEllb\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import date\n",
    "import random\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from one.api import ONE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import svd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics.functional import accuracy\n",
    "from torchmetrics import AUROC\n",
    "import lightning as L \n",
    "from lightning.pytorch.utilities import CombinedLoader\n",
    "\n",
    "from side_info_decoding.utils import (\n",
    "    set_seed, \n",
    "    load_data_from_pids, \n",
    "    sliding_window_over_trials\n",
    ")\n",
    "\n",
    "seed = 666\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71dcad29-f960-4a93-b648-0350dcf3f84a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324\n"
     ]
    }
   ],
   "source": [
    "from iblatlas.atlas import AllenAtlas\n",
    "ba = AllenAtlas()\n",
    "regions = np.unique(ba.regions.acronym[ba.regions.level == 7])\n",
    "print(len(regions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "731e7323-ee92-4c6f-b6b1-363cba7be0c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup\n",
    "# regions = [\"LP\", \"GRN\"]\n",
    "regions = [\"PO\", \"DG\", \"CA1\"]\n",
    "n_sess = 10\n",
    "out_path = Path(\"/mnt/3TB/yizi/cached_ibl_data\")\n",
    "one = ONE(base_url=\"https://openalyx.internationalbrainlab.org\", mode='remote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b67fea9-61e4-4262-9837-6b14dbfafc90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    }
   ],
   "source": [
    "with open(\"../biorxiv_plots/regions.txt\") as file:\n",
    "    regions = [line.rstrip() for line in file]\n",
    "print(len(regions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca831b-02cb-4c2f-a0d6-def21b5e8f46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download and cache data\n",
    "\n",
    "for roi_idx, roi in enumerate(regions):\n",
    "    \n",
    "    print(\"=================\")\n",
    "    print(f\"Downloading data in region {roi} ..\")\n",
    "    \n",
    "    pids = one.search_insertions(atlas_acronym=[roi], query_type='remote')\n",
    "    pids = list(pids)[:n_sess]\n",
    "    \n",
    "    # load choice\n",
    "    neural_dict, choice_dict = load_data_from_pids(\n",
    "        pids,\n",
    "        brain_region=roi.lower(),\n",
    "        behavior=\"choice\",\n",
    "        data_type=\"all_ks\",\n",
    "        n_t_bins = 40,\n",
    "    )\n",
    "    available_pids = list(neural_dict.keys())\n",
    "    \n",
    "    # load contrast\n",
    "    _, contrast_dict = load_data_from_pids(\n",
    "        pids,\n",
    "        brain_region=roi.lower(),\n",
    "        behavior=\"contrast\",\n",
    "        data_type=\"good_ks\",\n",
    "        n_t_bins = 40,\n",
    "    )\n",
    "\n",
    "    print(\"=================\")\n",
    "    print(f\"Downloaded {len(available_pids)} PIDs in region {roi} ..\")\n",
    "    \n",
    "    for _, pid in enumerate(available_pids):\n",
    "        xs, ys = neural_dict[pid], choice_dict[pid]\n",
    "        n_trials, n_units, n_t_bins = xs.shape\n",
    "        if n_units < 5:\n",
    "            continue\n",
    "        xs = sliding_window_over_trials(xs, half_window_size=0).squeeze()\n",
    "        ys = sliding_window_over_trials(ys, half_window_size=0).squeeze()\n",
    "        xs, ys = torch.tensor(xs), torch.tensor(ys)\n",
    "        \n",
    "        contrast_dict[pid] = np.nan_to_num(contrast_dict[pid], 0)\n",
    "        contrast_dict[pid].T[0] *= -1\n",
    "        contrast = contrast_dict[pid].sum(1)\n",
    "        \n",
    "        # INCORPORATE CHANGE HERE!\n",
    "        contrast_mask_dict = {}\n",
    "        for lvl in np.unique(np.abs(contrast)):\n",
    "            contrast_mask_dict.update(\n",
    "                {lvl: np.argwhere(np.abs(contrast) == lvl).flatten()}\n",
    "            )\n",
    "            \n",
    "        path = out_path/roi\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "            \n",
    "        data_dict = {}\n",
    "        data_dict.update({'contrast': contrast})\n",
    "        data_dict.update({'contrast_mask': contrast_mask_dict})\n",
    "        data_dict.update({'meta':\n",
    "            {\"n_trials\": n_trials, \"n_units\": n_units, \"n_t_bins\": n_t_bins}\n",
    "        })\n",
    "        xs_per_lvl, ys_per_lvl = {}, {}\n",
    "        xs_per_lvl.update({\"all\": xs})\n",
    "        ys_per_lvl.update({\"all\": ys})\n",
    "        for lvl in np.unique(np.abs(contrast)):\n",
    "            try:\n",
    "                xs_per_lvl.update({lvl: xs[contrast_mask_dict[lvl]]})\n",
    "                ys_per_lvl.update({lvl: ys[contrast_mask_dict[lvl]]})\n",
    "            except:\n",
    "                continue\n",
    "        data_dict.update({'neural_contrast': xs_per_lvl})\n",
    "        data_dict.update({'choice_contrast': ys_per_lvl})\n",
    "        np.save(path/f\"pid_{pid}.npy\", data_dict)\n",
    "        \n",
    "    print(\"=================\")\n",
    "    print(f\"Successfully cached all data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bc7962a-763a-45a1-be42-112b1649c327",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SessionDataset:\n",
    "    def __init__(self, dataset, roi_idx, pid_idx, **kargs):\n",
    "        self.xs, self.ys = dataset\n",
    "        self.n_trials, self.n_units, _ = self.xs.shape\n",
    "        self.roi_idx = roi_idx\n",
    "        self.pid_idx = pid_idx\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_trials\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return torch.tensor(self.xs[index]).to(DEVICE), torch.tensor(self.ys[index]).to(DEVICE), self.roi_idx, self.pid_idx\n",
    "    \n",
    "def dataloader(datasets, roi_idxs, pid_idxs, batch_size=32): \n",
    "    loaders = []\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        sess_dataset = SessionDataset(dataset, roi_idxs[i], pid_idxs[i])\n",
    "        loaders.append(DataLoader(\n",
    "            sess_dataset, \n",
    "            batch_size = batch_size,\n",
    "            shuffle=True, # SHUFFLE\n",
    "        ))\n",
    "    return loaders\n",
    "\n",
    "class Hier_Reduced_Rank_Model(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        n_roi,\n",
    "        n_units, \n",
    "        n_t_bin, \n",
    "        rank_V,\n",
    "        rank_B\n",
    "    ):\n",
    "        super(Hier_Reduced_Rank_Model, self).__init__()\n",
    "        \n",
    "        self.n_roi = n_roi\n",
    "        self.n_sess = len(n_units)\n",
    "        self.n_units = n_units\n",
    "        self.n_t_bin = n_t_bin\n",
    "        self.rank_V = rank_V\n",
    "        self.rank_B = rank_B\n",
    "        \n",
    "        self.Us = nn.ParameterList(\n",
    "            [nn.Parameter(torch.randn(self.n_units[i], self.rank_V)) for i in range(self.n_sess)]\n",
    "        )\n",
    "        self.A = nn.Parameter(torch.randn(self.n_roi, self.rank_V, self.rank_B)) \n",
    "        self.B = nn.Parameter(\n",
    "            torch.randn(self.rank_B, self.n_t_bin)\n",
    "        ) \n",
    "        self.intercepts = nn.ParameterList(\n",
    "            [nn.Parameter(torch.randn(1,)) for i in range(self.n_sess)]\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    # def forward(self, datasets):\n",
    "    #     pred_lst, gt_lst = [], []\n",
    "    #     for dataset in datasets:\n",
    "    #         X, Y, roi_idx, sess_idx = dataset\n",
    "    #         roi_idx = torch.unique(roi_idx)\n",
    "    #         sess_idx = torch.unique(sess_idx)\n",
    "    #         n_trials, n_units, n_t_bins = X.shape\n",
    "    #         self.Vs = torch.einsum(\"ijk,kt->ijt\", self.A, self.B)\n",
    "    #         self.Beta = torch.einsum(\"cr,rt->ct\", self.Us[sess_idx], self.Vs[roi_idx].squeeze()).to(DEVICE)\n",
    "    #         out = torch.einsum(\"ct,kct->k\", self.Beta, X)\n",
    "    #         out += self.intercepts[sess_idx].to(DEVICE) * torch.ones(n_trials).to(DEVICE)\n",
    "    #         out = self.sigmoid(out)\n",
    "    #         pred_lst.append(out)\n",
    "    #         gt_lst.append(Y)\n",
    "    #     return pred_lst, gt_lst\n",
    "    \n",
    "    def forward(self, dataset):\n",
    "        X, Y, roi_idx, sess_idx = dataset\n",
    "        roi_idx = torch.unique(roi_idx)\n",
    "        sess_idx = torch.unique(sess_idx)\n",
    "        n_trials, n_units, n_t_bins = X.shape\n",
    "        self.Vs = torch.einsum(\"ijk,kt->ijt\", self.A, self.B)\n",
    "        self.Beta = torch.einsum(\"cr,rt->ct\", self.Us[sess_idx], self.Vs[roi_idx].squeeze()).to(DEVICE)\n",
    "        out = torch.einsum(\"ct,kct->k\", self.Beta, X)\n",
    "        out += self.intercepts[sess_idx].to(DEVICE) * torch.ones(n_trials).to(DEVICE)\n",
    "        out = self.sigmoid(out)\n",
    "        return out, Y\n",
    "    \n",
    "class LitHierRRR(L.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    # def training_step(self, batch):\n",
    "    #     losses = 0\n",
    "    #     pred_lst, gt_lst = self.model(batch)\n",
    "    #     for i in range(len(batch)):\n",
    "    #         losses += nn.BCELoss()(pred_lst[i], gt_lst[i])\n",
    "    #     loss = losses / len(batch)\n",
    "    #     self.log(\"loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "    #     return loss\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = torch.zeros(len(batch))\n",
    "        for i, sess in enumerate(batch):\n",
    "            pred, gt = self.model(sess)\n",
    "            loss[i] = nn.BCELoss()(pred, gt)\n",
    "        loss = torch.mean(loss)\n",
    "        self.log(\"loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        accs, aucs = self._shared_eval_step(batch)\n",
    "        metrics = {\"val_acc\": np.mean(accs), \"val_auc\": np.mean(aucs)}\n",
    "        self.log_dict(metrics, on_step=False, on_epoch=True, prog_bar=True)\n",
    "    \n",
    "    def test_step(self, batch):\n",
    "        accs, aucs = self._shared_eval_step(batch)\n",
    "        for i in range(len(batch)):\n",
    "            print(f\"session {i} test_acc {accs[i]} test_auc {aucs[i]}\")\n",
    "\n",
    "    def _shared_eval_step(self, batch):\n",
    "        pred_lst, gt_lst = self.model(batch)\n",
    "        accs, aucs = [], []\n",
    "        for i in range(len(batch)):\n",
    "            auroc = AUROC(task=\"binary\")\n",
    "            acc = accuracy(pred_lst[i], gt_lst[i], task=\"binary\")\n",
    "            auc = auroc(pred_lst[i], gt_lst[i])\n",
    "            accs.append(acc)\n",
    "            aucs.append(auc)\n",
    "        return accs, aucs\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-2, weight_decay=1e-3)\n",
    "        # optimizer = optim.Adam(self.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d82d9ea-aadb-452c-aea5-ffcc3fc7b797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup\n",
    "regions = [\"LP\", \"GRN\", \"PO\", \"DG\", \"CA1\"]\n",
    "n_rank_V = 2\n",
    "n_rank_B = 2\n",
    "n_epochs = 500\n",
    "in_path = Path(\"/mnt/3TB/yizi/cached_ibl_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3741fa82-7728-4d2d-878f-0f015523bcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39383070-bdcc-4836-aa4d-8ce52faeb5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yizi/anaconda3/envs/clusterless/lib/python3.8/site-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                    | Params\n",
      "--------------------------------------------------\n",
      "0 | model | Hier_Reduced_Rank_Model | 7.1 K \n",
      "--------------------------------------------------\n",
      "7.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.1 K     Total params\n",
      "0.028     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================\n",
      "Started training on 1 / 5 folds ..\n",
      "=================\n",
      "Loading 10 PIDs in region LP:\n",
      "a6b71993-165b-4c43-845c-c062fe7d7a11\n",
      "ec2fbc3e-cb2b-48cb-a521-3a6ca15e244c\n",
      "bef05a5c-68c3-4513-87c7-b3151c88da8e\n",
      "7a620688-66cb-44d3-b79b-ccac1c8ba23e\n",
      "d0046384-16ea-4f69-bae9-165e8d0aeacf\n",
      "8c732bf2-639d-496c-bf82-464bc9c2d54b\n",
      "b72b22c2-6e9d-4604-9910-20c0e1a467d7\n",
      "8b31b4bd-003e-4816-a3bf-2df4cc3558f8\n",
      "1a924329-65aa-465d-b201-c2dd898aebd0\n",
      "22f26d69-0b30-450e-9618-ee801b720e0a\n",
      "=================\n",
      "Loading 10 PIDs in region GRN:\n",
      "e17db2b6-b778-4e2a-845c-c4d040b0c875\n",
      "c0e59477-43f0-4441-9f81-3a55ddad9dad\n",
      "df6012d0-d921-4d0a-af2a-2a91030d0f42\n",
      "cc72fdb7-92e8-47e6-9cea-94f27c0da2d8\n",
      "7332e6cf-9847-4aca-b2e3-d864989dd0fb\n",
      "04c9890f-2276-4c20-854f-305ff5c9b6cf\n",
      "6a098711-5423-4072-8909-7cff0e2d4531\n",
      "39883ded-f5a2-4f4f-a98e-fb138eb8433e\n",
      "aecd7612-b5c5-4ad2-9e76-e5b783387e47\n",
      "2e720cee-05cc-440e-a24b-13794b1ac01d\n",
      "=================\n",
      "Loading 7 PIDs in region PO:\n",
      "81950362-ed95-4662-997f-e119bbd594d1\n",
      "77121d92-6dde-4243-ab54-0a99efa22e99\n",
      "bef05a5c-68c3-4513-87c7-b3151c88da8e\n",
      "7a620688-66cb-44d3-b79b-ccac1c8ba23e\n",
      "4f922a5b-5014-455d-8cd5-7caed78af615\n",
      "8c732bf2-639d-496c-bf82-464bc9c2d54b\n",
      "8b31b4bd-003e-4816-a3bf-2df4cc3558f8\n",
      "=================\n",
      "Loading 9 PIDs in region DG:\n",
      "7a620688-66cb-44d3-b79b-ccac1c8ba23e\n",
      "d0046384-16ea-4f69-bae9-165e8d0aeacf\n",
      "8c732bf2-639d-496c-bf82-464bc9c2d54b\n",
      "49c2ea3d-2b50-4e8a-b124-9e190960784e\n",
      "c5b9e063-f640-4936-b851-f7602cb6659b\n",
      "b72b22c2-6e9d-4604-9910-20c0e1a467d7\n",
      "88e148d2-d554-42c2-9c41-cc6369f98c45\n",
      "a8a59fc3-a658-4db4-b5e8-09f1e4df03fd\n",
      "4836a465-c691-4852-a0b1-dcd2b1ce38a1\n",
      "=================\n",
      "Loading 10 PIDs in region CA1:\n",
      "7a620688-66cb-44d3-b79b-ccac1c8ba23e\n",
      "d0046384-16ea-4f69-bae9-165e8d0aeacf\n",
      "8c732bf2-639d-496c-bf82-464bc9c2d54b\n",
      "49c2ea3d-2b50-4e8a-b124-9e190960784e\n",
      "c5b9e063-f640-4936-b851-f7602cb6659b\n",
      "b72b22c2-6e9d-4604-9910-20c0e1a467d7\n",
      "d552cffa-b662-40bd-b1e3-98d0a8face2c\n",
      "18d316bf-d322-4c5c-814e-a58147f7bf5f\n",
      "a8a59fc3-a658-4db4-b5e8-09f1e4df03fd\n",
      "4836a465-c691-4852-a0b1-dcd2b1ce38a1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yizi/anaconda3/envs/clusterless/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/yizi/anaconda3/envs/clusterless/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (9) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d816012a87834265b6e9f8bbf0c252e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28030/937298487.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self.xs[index]).to(DEVICE), torch.tensor(self.ys[index]).to(DEVICE), self.roi_idx, self.pid_idx\n"
     ]
    }
   ],
   "source": [
    "# prep data for fitting hier-RRR on trials with diff contrast\n",
    "\n",
    "res_dict = {}\n",
    "# for lvl in [\"all\", .0625, .125, .25, 1.]:\n",
    "for lvl in [\"all\"]:\n",
    "    \n",
    "#     print(\"=================\")\n",
    "#     print(f\"Started training on trials with contrast {lvl} ..\")\n",
    "\n",
    "#     lst_datasets, lst_units, lst_regions, lst_sessions, lst_region_names, lst_pids = [], [], [], [], [], []\n",
    "\n",
    "#     pid_idx = 0\n",
    "#     for roi_idx, roi in enumerate(regions):\n",
    "\n",
    "#         f_names = os.listdir(in_path/roi)\n",
    "#         pids = [f_name.split(\"_\")[1].split(\".\")[0] for f_name in f_names]\n",
    "\n",
    "#         print(\"=================\")\n",
    "#         print(f\"Loading {len(pids)} PIDs in region {roi}:\")\n",
    "#         for pid in pids:\n",
    "#             print(pid)\n",
    "\n",
    "#         data_dict = np.load(in_path/roi/f\"pid_{pid}.npy\", allow_pickle=True).item()\n",
    "\n",
    "#         for _, pid in enumerate(pids):\n",
    "#             xs = data_dict[\"neural_contrast\"][lvl]\n",
    "#             ys = data_dict[\"choice_contrast\"][lvl]\n",
    "#             lst_datasets.append((xs, ys))\n",
    "#             lst_units.append(data_dict[\"meta\"][\"n_units\"])\n",
    "#             lst_regions.append(roi_idx)\n",
    "#             lst_region_names.append(roi)\n",
    "#             lst_sessions.append(pid_idx)\n",
    "#             lst_pids.append(pid)\n",
    "#             pid_idx += 1 \n",
    "\n",
    "#     train_loaders = dataloader(lst_datasets, lst_regions, lst_sessions, batch_size=128)\n",
    "#     train_loaders = CombinedLoader(train_loaders, mode=\"min_size\")\n",
    "\n",
    "#     hier_rrr = Hier_Reduced_Rank_Model(\n",
    "#         n_roi = len(regions),\n",
    "#         n_units = lst_units, \n",
    "#         n_t_bin = data_dict[\"meta\"][\"n_t_bins\"], \n",
    "#         rank_V = n_rank_V,\n",
    "#         rank_B = n_rank_B\n",
    "#     )\n",
    "\n",
    "#     lit_hier_rrr = LitHierRRR(hier_rrr)\n",
    "#     trainer = L.Trainer(max_epochs=n_epochs)\n",
    "#     trainer.fit(model=lit_hier_rrr, \n",
    "#                 train_dataloaders=train_loaders)\n",
    "\n",
    "#     Us = [hier_rrr.Us[pid_idx].cpu().detach().numpy() for pid_idx in lst_sessions]\n",
    "#     Vs = hier_rrr.Vs.cpu().detach().numpy()\n",
    "#     B = hier_rrr.Vs.cpu().detach().numpy()\n",
    "\n",
    "#     svd_Us, svd_Vs = [], []\n",
    "#     for pid_idx in lst_sessions:\n",
    "#         roi_idx = lst_regions[pid_idx]\n",
    "#         W = Us[pid_idx] @ Vs[roi_idx]\n",
    "#         U, S, V = svd(W)\n",
    "#         svd_Vs.append(np.diag(S[:n_rank_V]) @ V[:n_rank_V, :])\n",
    "#         svd_Us.append(U[:, :n_rank_V] @ np.diag(S[:n_rank_V]))\n",
    "#     svd_Vs = np.array(svd_Vs)\n",
    "#     svd_Us = np.array(svd_Us)\n",
    "    \n",
    "#     fig, axes = plt.subplots(len(regions)+2, 1, figsize=(5, 5*len(regions)))\n",
    "#     for i, roi_idx in enumerate(np.unique(lst_regions)):\n",
    "#         mask = np.array(lst_regions) == roi_idx\n",
    "#         axes[i].plot(np.abs(svd_Vs[mask].mean(0)[0]))\n",
    "#         axes[i].set_title(f\"{regions[roi_idx]} (contrast = {lvl})\")\n",
    "#     axes[2].plot(np.abs(B[0].T))\n",
    "#     axes[2].set_title(\"B (rank 1)\")\n",
    "#     axes[3].plot(np.abs(B[1].T))\n",
    "#     axes[3].set_title(\"B (rank 2)\")\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "#     res_dict.update({lvl: {}})\n",
    "#     res_dict[lvl].update({\"pid_idxs\": lst_sessions})\n",
    "#     res_dict[lvl].update({\"regions_idxs\": lst_regions})\n",
    "#     res_dict[lvl].update({\"region_names\": lst_region_names})\n",
    "#     res_dict[lvl].update({\"pids\": lst_pids})\n",
    "#     res_dict[lvl].update({\"svd_Vs\": svd_Vs})\n",
    "#     res_dict[lvl].update({\"svd_Us\": svd_Us})\n",
    "#     res_dict[lvl].update({\"B\": B})\n",
    "#     res_dict[lvl].update({\"S\": S})\n",
    "    \n",
    "#     print(\"=================\")\n",
    "#     print(f\"Finished training on trials with contrast {lvl} ..\")\n",
    "    \n",
    "    # 5-fold CV\n",
    "    n_folds = 5\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    xval_dict, hier_rrr_B = {}, []\n",
    "    for fold_idx in range(n_folds):\n",
    "\n",
    "        print(\"=================\")\n",
    "        print(f\"Started training on {fold_idx+1} / {n_folds} folds ..\")\n",
    "\n",
    "        train_datasets, test_datasets = [], []\n",
    "        lst_units, lst_regions, lst_sessions, lst_region_names, lst_pids = [], [], [], [], []\n",
    "\n",
    "        pid_idx = 0\n",
    "        for roi_idx, roi in enumerate(regions):\n",
    "\n",
    "            f_names = os.listdir(in_path/roi)\n",
    "            pids = [f_name.split(\"_\")[1].split(\".\")[0] for f_name in f_names]\n",
    "\n",
    "            print(\"=================\")\n",
    "            print(f\"Loading {len(pids)} PIDs in region {roi}:\")\n",
    "            for pid in pids:\n",
    "                print(pid)\n",
    "\n",
    "            data_dict = np.load(in_path/roi/f\"pid_{pid}.npy\", allow_pickle=True).item()\n",
    "\n",
    "            for _, pid in enumerate(pids):\n",
    "                xs = data_dict[\"neural_contrast\"][lvl]\n",
    "                ys = data_dict[\"choice_contrast\"][lvl]\n",
    "                for counter, (train, test) in enumerate(skf.split(xs, ys)):\n",
    "                    if counter == fold_idx:\n",
    "                        train_xs, test_xs = xs[train], xs[test]\n",
    "                        train_ys, test_ys = ys[train], ys[test]\n",
    "                train_datasets.append((train_xs, train_ys))\n",
    "                test_datasets.append((test_xs, test_ys))\n",
    "                lst_units.append(data_dict[\"meta\"][\"n_units\"])\n",
    "                lst_regions.append(roi_idx)\n",
    "                lst_region_names.append(roi)\n",
    "                lst_sessions.append(pid_idx)\n",
    "                lst_pids.append(pid)\n",
    "                pid_idx += 1\n",
    "\n",
    "        train_loaders = dataloader(train_datasets, lst_regions, lst_sessions, batch_size=64)\n",
    "        test_loaders = dataloader(test_datasets, lst_regions, lst_sessions, batch_size=64)\n",
    "        train_loaders = CombinedLoader(train_loaders, mode=\"max_size_cycle\")\n",
    "        test_loaders = CombinedLoader(test_loaders, mode=\"max_size_cycle\")\n",
    "\n",
    "        hier_rrr = Hier_Reduced_Rank_Model(\n",
    "            n_roi = len(regions),\n",
    "            n_units = lst_units, \n",
    "            n_t_bin = data_dict[\"meta\"][\"n_t_bins\"], \n",
    "            rank_V = n_rank_V,\n",
    "            rank_B = n_rank_B\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        lit_hier_rrr = LitHierRRR(hier_rrr)\n",
    "        trainer = L.Trainer(max_epochs=n_epochs)\n",
    "        trainer.fit(model=lit_hier_rrr, \n",
    "                    train_dataloaders=train_loaders)\n",
    "        \n",
    "        hier_rrr_B.append(hier_rrr.B.cpu().detach().numpy())\n",
    "        \n",
    "        # accs_per_batch, aucs_per_batch = [], []\n",
    "        # for batch in test_loaders:\n",
    "        #     accs, aucs = [], []\n",
    "        #     pred_lst, gt_lst = hier_rrr(batch[0])\n",
    "        #     for i in range(len(batch[0])):\n",
    "        #         auroc = AUROC(task=\"binary\")\n",
    "        #         accs.append(accuracy(pred_lst[i], gt_lst[i], task=\"binary\").item())\n",
    "        #         aucs.append(auroc(pred_lst[i], gt_lst[i]).item())\n",
    "        #     accs_per_batch.append(accs)\n",
    "        #     aucs_per_batch.append(aucs)\n",
    "        # test_accs = np.mean(accs_per_batch, 0)\n",
    "        # test_aucs = np.mean(aucs_per_batch, 0)\n",
    "        # print(\"Accuracy: \", test_accs)\n",
    "        # print(\"AUC: \", test_aucs)\n",
    "        \n",
    "        accs_per_batch = []\n",
    "        for batch in test_loaders:\n",
    "            accs = []\n",
    "            for i, sess in enumerate(batch[0]):\n",
    "                prob, gt = hier_rrr(sess)\n",
    "                prob = prob.cpu().detach().numpy()\n",
    "                pred = [1 if p > 0.5 else 0 for p in prob]\n",
    "                gt = gt.cpu().detach().numpy()\n",
    "                accs.append(balanced_accuracy_score(gt, pred))\n",
    "            accs_per_batch.append(accs)\n",
    "        test_accs = np.mean(accs_per_batch, 0)\n",
    "        print(\"Accuracy: \", test_accs)\n",
    "\n",
    "        xval_dict.update({fold_idx: {}})\n",
    "        xval_dict[fold_idx].update({\"accs\": test_accs})\n",
    "        xval_dict[fold_idx].update({\"pid_idxs\": lst_sessions})\n",
    "        xval_dict[fold_idx].update({\"regions_idxs\": lst_regions})\n",
    "        xval_dict[fold_idx].update({\"region_names\": lst_region_names})\n",
    "        xval_dict[fold_idx].update({\"pids\": lst_pids})\n",
    "\n",
    "        print(\"=================\")\n",
    "        print(f\"Finished training on {fold_idx+1} / {n_folds} folds ..\")\n",
    "        # break\n",
    "    break\n",
    "\n",
    "    # np.save(in_path/f\"xval_contrast_{lvl}.npy\", xval_dict)\n",
    "    \n",
    "# np.save(in_path/f\"res_{date.today()}.npy\", res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bad2489-14f6-4f36-973d-9835021e01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(hier_rrr_B, 0).T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f040a5-e801-477f-a910-83f966b4c47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(xval_dict[0]).iloc[:,:2] / 5\n",
    "for fold in range(1,5):\n",
    "    df += pd.DataFrame(xval_dict[fold]).iloc[:,:2] / 5\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e471c0ce-7152-4f7a-891b-8e2e715edb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. shuffle train loader\n",
    "# 2. change training_step\n",
    "# 3. change test eval\n",
    "# 4. remove AUC -> change acc to balanced acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9de85a9-5190-4f9d-92a0-fbd24c30cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eig = np.power(S, 2)\n",
    "# print(eig / eig.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ced2573-57ff-4be5-814d-5c741afd8db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d98be78-1e0f-4dfe-b0ed-46036cbfab2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dce3b42-6bab-4264-96b9-f1c0fab4f16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rank_V = 10\n",
    "n_rank_B = 10\n",
    "n_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e731abd0-51c6-4e17-9c7f-a08f07403764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2276565-4c22-458f-b7dd-8df769f48971",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yizi/anaconda3/envs/clusterless/lib/python3.8/site-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                    | Params\n",
      "--------------------------------------------------\n",
      "0 | model | Hier_Reduced_Rank_Model | 12.8 K\n",
      "--------------------------------------------------\n",
      "12.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.8 K    Total params\n",
      "0.051     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================\n",
      "Started training on 1 / 5 folds ..\n",
      "=================\n",
      "Loading 10 PIDs in region LP:\n",
      "a6b71993-165b-4c43-845c-c062fe7d7a11\n",
      "ec2fbc3e-cb2b-48cb-a521-3a6ca15e244c\n",
      "bef05a5c-68c3-4513-87c7-b3151c88da8e\n",
      "7a620688-66cb-44d3-b79b-ccac1c8ba23e\n",
      "d0046384-16ea-4f69-bae9-165e8d0aeacf\n",
      "8c732bf2-639d-496c-bf82-464bc9c2d54b\n",
      "b72b22c2-6e9d-4604-9910-20c0e1a467d7\n",
      "8b31b4bd-003e-4816-a3bf-2df4cc3558f8\n",
      "1a924329-65aa-465d-b201-c2dd898aebd0\n",
      "22f26d69-0b30-450e-9618-ee801b720e0a\n",
      "=================\n",
      "Loading 10 PIDs in region GRN:\n",
      "e17db2b6-b778-4e2a-845c-c4d040b0c875\n",
      "c0e59477-43f0-4441-9f81-3a55ddad9dad\n",
      "df6012d0-d921-4d0a-af2a-2a91030d0f42\n",
      "cc72fdb7-92e8-47e6-9cea-94f27c0da2d8\n",
      "7332e6cf-9847-4aca-b2e3-d864989dd0fb\n",
      "04c9890f-2276-4c20-854f-305ff5c9b6cf\n",
      "6a098711-5423-4072-8909-7cff0e2d4531\n",
      "39883ded-f5a2-4f4f-a98e-fb138eb8433e\n",
      "aecd7612-b5c5-4ad2-9e76-e5b783387e47\n",
      "2e720cee-05cc-440e-a24b-13794b1ac01d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yizi/anaconda3/envs/clusterless/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/yizi/anaconda3/envs/clusterless/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6694fc674e8f40869deba6dfd3aa15cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_102572/2477955401.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self.xs[index]).to(DEVICE), torch.tensor(self.ys[index]).to(DEVICE), self.roi_idx, self.pid_idx\n",
      "`Trainer.fit` stopped: `max_epochs=1000` reached.\n",
      "/home/yizi/anaconda3/envs/clusterless/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yizi/anaconda3/envs/clusterless/lib/python3.8/site-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                    | Params\n",
      "--------------------------------------------------\n",
      "0 | model | Hier_Reduced_Rank_Model | 12.8 K\n",
      "--------------------------------------------------\n",
      "12.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.8 K    Total params\n",
      "0.051     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  [0.84375    0.84375    0.85546875 0.859375   0.84765625 0.859375\n",
      " 0.85546875 0.8515625  0.85546875 0.859375   0.953125   0.8342014\n",
      " 0.88975695 0.8858507  0.88975695 0.83810765 0.94921875 0.8936632\n",
      " 0.89756945 0.94921875]\n",
      "AUC:  [0.38500669 0.38821954 0.38674699 0.38299866 0.38447122 0.38527443\n",
      " 0.38781794 0.38661312 0.38567604 0.38607764 0.98336188 0.94948268\n",
      " 0.9498497  0.94899332 0.949238   0.94960502 0.98409591 0.98519697\n",
      " 0.94813695 0.98409591]\n",
      "=================\n",
      "Finished training on 1 / 5 folds ..\n",
      "=================\n",
      "Started training on 2 / 5 folds ..\n",
      "=================\n",
      "Loading 10 PIDs in region LP:\n",
      "a6b71993-165b-4c43-845c-c062fe7d7a11\n",
      "ec2fbc3e-cb2b-48cb-a521-3a6ca15e244c\n",
      "bef05a5c-68c3-4513-87c7-b3151c88da8e\n",
      "7a620688-66cb-44d3-b79b-ccac1c8ba23e\n",
      "d0046384-16ea-4f69-bae9-165e8d0aeacf\n",
      "8c732bf2-639d-496c-bf82-464bc9c2d54b\n",
      "b72b22c2-6e9d-4604-9910-20c0e1a467d7\n",
      "8b31b4bd-003e-4816-a3bf-2df4cc3558f8\n",
      "1a924329-65aa-465d-b201-c2dd898aebd0\n",
      "22f26d69-0b30-450e-9618-ee801b720e0a\n",
      "=================\n",
      "Loading 10 PIDs in region GRN:\n",
      "e17db2b6-b778-4e2a-845c-c4d040b0c875\n",
      "c0e59477-43f0-4441-9f81-3a55ddad9dad\n",
      "df6012d0-d921-4d0a-af2a-2a91030d0f42\n",
      "cc72fdb7-92e8-47e6-9cea-94f27c0da2d8\n",
      "7332e6cf-9847-4aca-b2e3-d864989dd0fb\n",
      "04c9890f-2276-4c20-854f-305ff5c9b6cf\n",
      "6a098711-5423-4072-8909-7cff0e2d4531\n",
      "39883ded-f5a2-4f4f-a98e-fb138eb8433e\n",
      "aecd7612-b5c5-4ad2-9e76-e5b783387e47\n",
      "2e720cee-05cc-440e-a24b-13794b1ac01d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yizi/anaconda3/envs/clusterless/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/yizi/anaconda3/envs/clusterless/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4be6718953640299361a59e731d676e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_102572/2477955401.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self.xs[index]).to(DEVICE), torch.tensor(self.ys[index]).to(DEVICE), self.roi_idx, self.pid_idx\n",
      "`Trainer.fit` stopped: `max_epochs=1000` reached.\n",
      "/home/yizi/anaconda3/envs/clusterless/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yizi/anaconda3/envs/clusterless/lib/python3.8/site-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                    | Params\n",
      "--------------------------------------------------\n",
      "0 | model | Hier_Reduced_Rank_Model | 12.8 K\n",
      "--------------------------------------------------\n",
      "12.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.8 K    Total params\n",
      "0.051     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  [0.8359375  0.83203125 0.8203125  0.8359375  0.8359375  0.828125\n",
      " 0.82421875 0.828125   0.828125   0.83203125 0.9453125  0.9375\n",
      " 0.94140625 0.93359375 0.9453125  0.94140625 0.94140625 0.9375\n",
      " 0.94140625 0.94140625]\n",
      "AUC:  [0.34703075 0.34544008 0.34424708 0.33722163 0.3400053  0.33947508\n",
      " 0.3468982  0.34597031 0.33987275 0.34663309 0.97936625 0.97555883\n",
      " 0.97678703 0.97408499 0.97973471 0.98157701 0.98255957 0.97764677\n",
      " 0.97899779 0.97936625]\n",
      "=================\n",
      "Finished training on 2 / 5 folds ..\n",
      "=================\n",
      "Started training on 3 / 5 folds ..\n",
      "=================\n",
      "Loading 10 PIDs in region LP:\n",
      "a6b71993-165b-4c43-845c-c062fe7d7a11\n",
      "ec2fbc3e-cb2b-48cb-a521-3a6ca15e244c\n",
      "bef05a5c-68c3-4513-87c7-b3151c88da8e\n",
      "7a620688-66cb-44d3-b79b-ccac1c8ba23e\n",
      "d0046384-16ea-4f69-bae9-165e8d0aeacf\n",
      "8c732bf2-639d-496c-bf82-464bc9c2d54b\n",
      "b72b22c2-6e9d-4604-9910-20c0e1a467d7\n",
      "8b31b4bd-003e-4816-a3bf-2df4cc3558f8\n",
      "1a924329-65aa-465d-b201-c2dd898aebd0\n",
      "22f26d69-0b30-450e-9618-ee801b720e0a\n",
      "=================\n",
      "Loading 10 PIDs in region GRN:\n",
      "e17db2b6-b778-4e2a-845c-c4d040b0c875\n",
      "c0e59477-43f0-4441-9f81-3a55ddad9dad\n",
      "df6012d0-d921-4d0a-af2a-2a91030d0f42\n",
      "cc72fdb7-92e8-47e6-9cea-94f27c0da2d8\n",
      "7332e6cf-9847-4aca-b2e3-d864989dd0fb\n",
      "04c9890f-2276-4c20-854f-305ff5c9b6cf\n",
      "6a098711-5423-4072-8909-7cff0e2d4531\n",
      "39883ded-f5a2-4f4f-a98e-fb138eb8433e\n",
      "aecd7612-b5c5-4ad2-9e76-e5b783387e47\n",
      "2e720cee-05cc-440e-a24b-13794b1ac01d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yizi/anaconda3/envs/clusterless/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/yizi/anaconda3/envs/clusterless/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d69976d77b4dd3b8f48c2e8ac5a77b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_102572/2477955401.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self.xs[index]).to(DEVICE), torch.tensor(self.ys[index]).to(DEVICE), self.roi_idx, self.pid_idx\n",
      "`Trainer.fit` stopped: `max_epochs=1000` reached.\n",
      "/home/yizi/anaconda3/envs/clusterless/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yizi/anaconda3/envs/clusterless/lib/python3.8/site-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                    | Params\n",
      "--------------------------------------------------\n",
      "0 | model | Hier_Reduced_Rank_Model | 12.8 K\n",
      "--------------------------------------------------\n",
      "12.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.8 K    Total params\n",
      "0.051     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  [0.35546875 0.35546875 0.35546875 0.35546875 0.35546875 0.35546875\n",
      " 0.35546875 0.35546875 0.35546875 0.35546875 0.96484375 0.96484375\n",
      " 0.96484375 0.96484375 0.96484375 0.96484375 0.96484375 0.96484375\n",
      " 0.96484375 0.96484375]\n",
      "AUC:  [0.39912513 0.39899258 0.39899258 0.39925769 0.39912513 0.39925769\n",
      " 0.39899258 0.39793213 0.39886002 0.39939024 0.99606976 0.99582412\n",
      " 0.99582412 0.99582412 0.99582412 0.99582412 0.99582412 0.99582412\n",
      " 0.99582412 0.99582412]\n",
      "=================\n",
      "Finished training on 3 / 5 folds ..\n",
      "=================\n",
      "Started training on 4 / 5 folds ..\n",
      "=================\n",
      "Loading 10 PIDs in region LP:\n",
      "a6b71993-165b-4c43-845c-c062fe7d7a11\n",
      "ec2fbc3e-cb2b-48cb-a521-3a6ca15e244c\n",
      "bef05a5c-68c3-4513-87c7-b3151c88da8e\n",
      "7a620688-66cb-44d3-b79b-ccac1c8ba23e\n",
      "d0046384-16ea-4f69-bae9-165e8d0aeacf\n",
      "8c732bf2-639d-496c-bf82-464bc9c2d54b\n",
      "b72b22c2-6e9d-4604-9910-20c0e1a467d7\n",
      "8b31b4bd-003e-4816-a3bf-2df4cc3558f8\n",
      "1a924329-65aa-465d-b201-c2dd898aebd0\n",
      "22f26d69-0b30-450e-9618-ee801b720e0a\n",
      "=================\n",
      "Loading 10 PIDs in region GRN:\n",
      "e17db2b6-b778-4e2a-845c-c4d040b0c875\n",
      "c0e59477-43f0-4441-9f81-3a55ddad9dad\n",
      "df6012d0-d921-4d0a-af2a-2a91030d0f42\n",
      "cc72fdb7-92e8-47e6-9cea-94f27c0da2d8\n",
      "7332e6cf-9847-4aca-b2e3-d864989dd0fb\n",
      "04c9890f-2276-4c20-854f-305ff5c9b6cf\n",
      "6a098711-5423-4072-8909-7cff0e2d4531\n",
      "39883ded-f5a2-4f4f-a98e-fb138eb8433e\n",
      "aecd7612-b5c5-4ad2-9e76-e5b783387e47\n",
      "2e720cee-05cc-440e-a24b-13794b1ac01d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yizi/anaconda3/envs/clusterless/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/yizi/anaconda3/envs/clusterless/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed6085a8b9742e1a33f5a892504920d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_102572/2477955401.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self.xs[index]).to(DEVICE), torch.tensor(self.ys[index]).to(DEVICE), self.roi_idx, self.pid_idx\n",
      "`Trainer.fit` stopped: `max_epochs=1000` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yizi/anaconda3/envs/clusterless/lib/python3.8/site-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                    | Params\n",
      "--------------------------------------------------\n",
      "0 | model | Hier_Reduced_Rank_Model | 12.8 K\n",
      "--------------------------------------------------\n",
      "12.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.8 K    Total params\n",
      "0.051     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  [0.7421875 0.7421875 0.7421875 0.7421875 0.7421875 0.7421875 0.7421875\n",
      " 0.7421875 0.7421875 0.7421875 0.90625   0.9140625 0.90625   0.890625\n",
      " 0.90625   0.8984375 0.9140625 0.90625   0.90625   0.90625  ]\n",
      "AUC:  [0.81521739 0.81601273 0.81495228 0.8154825  0.81442206 0.8154825\n",
      " 0.81601273 0.81495228 0.81574761 0.81495228 0.96525569 0.96452165\n",
      " 0.96525569 0.9696599  0.96550037 0.96354294 0.9640323  0.96256423\n",
      " 0.96525569 0.96525569]\n",
      "=================\n",
      "Finished training on 4 / 5 folds ..\n",
      "=================\n",
      "Started training on 5 / 5 folds ..\n",
      "=================\n",
      "Loading 10 PIDs in region LP:\n",
      "a6b71993-165b-4c43-845c-c062fe7d7a11\n",
      "ec2fbc3e-cb2b-48cb-a521-3a6ca15e244c\n",
      "bef05a5c-68c3-4513-87c7-b3151c88da8e\n",
      "7a620688-66cb-44d3-b79b-ccac1c8ba23e\n",
      "d0046384-16ea-4f69-bae9-165e8d0aeacf\n",
      "8c732bf2-639d-496c-bf82-464bc9c2d54b\n",
      "b72b22c2-6e9d-4604-9910-20c0e1a467d7\n",
      "8b31b4bd-003e-4816-a3bf-2df4cc3558f8\n",
      "1a924329-65aa-465d-b201-c2dd898aebd0\n",
      "22f26d69-0b30-450e-9618-ee801b720e0a\n",
      "=================\n",
      "Loading 10 PIDs in region GRN:\n",
      "e17db2b6-b778-4e2a-845c-c4d040b0c875\n",
      "c0e59477-43f0-4441-9f81-3a55ddad9dad\n",
      "df6012d0-d921-4d0a-af2a-2a91030d0f42\n",
      "cc72fdb7-92e8-47e6-9cea-94f27c0da2d8\n",
      "7332e6cf-9847-4aca-b2e3-d864989dd0fb\n",
      "04c9890f-2276-4c20-854f-305ff5c9b6cf\n",
      "6a098711-5423-4072-8909-7cff0e2d4531\n",
      "39883ded-f5a2-4f4f-a98e-fb138eb8433e\n",
      "aecd7612-b5c5-4ad2-9e76-e5b783387e47\n",
      "2e720cee-05cc-440e-a24b-13794b1ac01d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yizi/anaconda3/envs/clusterless/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/yizi/anaconda3/envs/clusterless/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde8262e90e244848360fded063483e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_102572/2477955401.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self.xs[index]).to(DEVICE), torch.tensor(self.ys[index]).to(DEVICE), self.roi_idx, self.pid_idx\n",
      "`Trainer.fit` stopped: `max_epochs=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  [0.75      0.75      0.75      0.75      0.75      0.75      0.75\n",
      " 0.75      0.75      0.75      0.953125  0.9609375 0.953125  0.953125\n",
      " 0.953125  0.9609375 0.953125  0.953125  0.953125  0.9609375]\n",
      "AUC:  [0.81866384 0.81813362 0.81919406 0.81919406 0.81919406 0.81892895\n",
      " 0.81892895 0.81813362 0.81839873 0.81892895 0.96838235 0.97377451\n",
      " 0.96936275 0.96862745 0.96838235 0.97034314 0.96862745 0.96887255\n",
      " 0.96911765 0.97303922]\n",
      "=================\n",
      "Finished training on 5 / 5 folds ..\n"
     ]
    }
   ],
   "source": [
    "# prep data for x-val\n",
    "\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "xval_dict = {}\n",
    "for fold_idx in range(n_folds):\n",
    "    \n",
    "    print(\"=================\")\n",
    "    print(f\"Started training on {fold_idx+1} / {n_folds} folds ..\")\n",
    "    \n",
    "    train_datasets, test_datasets = [], []\n",
    "    lst_units, lst_regions, lst_sessions, lst_region_names, lst_pids = [], [], [], [], []\n",
    "\n",
    "    pid_idx = 0\n",
    "    for roi_idx, roi in enumerate(regions):\n",
    "\n",
    "        f_names = os.listdir(in_path/roi)\n",
    "        pids = [f_name.split(\"_\")[1].split(\".\")[0] for f_name in f_names]\n",
    "\n",
    "        print(\"=================\")\n",
    "        print(f\"Loading {len(pids)} PIDs in region {roi}:\")\n",
    "        for pid in pids:\n",
    "            print(pid)\n",
    "\n",
    "        data_dict = np.load(in_path/roi/f\"pid_{pid}.npy\", allow_pickle=True).item()\n",
    "\n",
    "        for _, pid in enumerate(pids):\n",
    "            xs = data_dict[\"neural_contrast\"][\"all\"]\n",
    "            ys = data_dict[\"choice_contrast\"][\"all\"]\n",
    "            for counter, (train, test) in enumerate(skf.split(xs, ys)):\n",
    "                if counter == fold_idx:\n",
    "                    train_xs, test_xs = xs[train], xs[test]\n",
    "                    train_ys, test_ys = ys[train], ys[test]\n",
    "            train_datasets.append((train_xs, train_ys))\n",
    "            test_datasets.append((test_xs, test_ys))\n",
    "            lst_units.append(data_dict[\"meta\"][\"n_units\"])\n",
    "            lst_regions.append(roi_idx)\n",
    "            lst_region_names.append(roi)\n",
    "            lst_sessions.append(pid_idx)\n",
    "            lst_pids.append(pid)\n",
    "            pid_idx += 1\n",
    "            \n",
    "    train_loaders = dataloader(train_datasets, lst_regions, lst_sessions, batch_size=128)\n",
    "    test_loaders = dataloader(test_datasets, lst_regions, lst_sessions, batch_size=128)\n",
    "    train_loaders = CombinedLoader(train_loaders, mode=\"min_size\")\n",
    "    test_loaders = CombinedLoader(test_loaders, mode=\"min_size\")\n",
    "\n",
    "    hier_rrr = Hier_Reduced_Rank_Model(\n",
    "        n_roi = len(regions),\n",
    "        n_units = lst_units, \n",
    "        n_t_bin = data_dict[\"meta\"][\"n_t_bins\"], \n",
    "        rank_V = n_rank_V,\n",
    "        rank_B = n_rank_B\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    lit_hier_rrr = LitHierRRR(hier_rrr)\n",
    "    trainer = L.Trainer(max_epochs=n_epochs)\n",
    "    trainer.fit(model=lit_hier_rrr, \n",
    "                train_dataloaders=train_loaders)\n",
    "    \n",
    "    accs_per_batch, aucs_per_batch = [], []\n",
    "    for batch in test_loaders:\n",
    "        accs, aucs = [], []\n",
    "        pred_lst, gt_lst = hier_rrr(batch[0])\n",
    "        for i in range(len(batch[0])):\n",
    "            auroc = AUROC(task=\"binary\")\n",
    "            accs.append(accuracy(pred_lst[i], gt_lst[i], task=\"binary\").item())\n",
    "            aucs.append(auroc(pred_lst[i], gt_lst[i]).item())\n",
    "        accs_per_batch.append(accs)\n",
    "        aucs_per_batch.append(aucs)\n",
    "    test_accs = np.mean(accs_per_batch, 0)\n",
    "    test_aucs = np.mean(aucs_per_batch, 0)\n",
    "    print(\"Accuracy: \", test_accs)\n",
    "    print(\"AUC: \", test_aucs)\n",
    "    \n",
    "    xval_dict.update({fold_idx: {}})\n",
    "    xval_dict[fold_idx].update({\"accs\": test_accs})\n",
    "    xval_dict[fold_idx].update({\"aucs\": test_aucs})\n",
    "    xval_dict[fold_idx].update({\"pid_idxs\": lst_sessions})\n",
    "    xval_dict[fold_idx].update({\"regions_idxs\": lst_regions})\n",
    "    xval_dict[fold_idx].update({\"region_names\": lst_region_names})\n",
    "    xval_dict[fold_idx].update({\"pids\": lst_pids})\n",
    "    \n",
    "    print(\"=================\")\n",
    "    print(f\"Finished training on {fold_idx+1} / {n_folds} folds ..\")\n",
    "\n",
    "np.save(in_path/f\"xval_rankB_{n_rank_V}_rankV_{n_rank_V}.npy\", xval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed669fbf-cd8a-4549-b756-37d85cbe59c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accs</th>\n",
       "      <th>aucs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.705469</td>\n",
       "      <td>0.553009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.704688</td>\n",
       "      <td>0.553360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.704688</td>\n",
       "      <td>0.552827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.708594</td>\n",
       "      <td>0.550831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.706250</td>\n",
       "      <td>0.551444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.707031</td>\n",
       "      <td>0.551684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.705469</td>\n",
       "      <td>0.553730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.705469</td>\n",
       "      <td>0.552720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.706250</td>\n",
       "      <td>0.551711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.707813</td>\n",
       "      <td>0.553196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.944531</td>\n",
       "      <td>0.978487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.922309</td>\n",
       "      <td>0.971832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.931076</td>\n",
       "      <td>0.971416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.925608</td>\n",
       "      <td>0.971438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.931858</td>\n",
       "      <td>0.971736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.920747</td>\n",
       "      <td>0.972178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.944531</td>\n",
       "      <td>0.979028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.931076</td>\n",
       "      <td>0.978021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.932639</td>\n",
       "      <td>0.971466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.944531</td>\n",
       "      <td>0.979516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accs      aucs\n",
       "0   0.705469  0.553009\n",
       "1   0.704688  0.553360\n",
       "2   0.704688  0.552827\n",
       "3   0.708594  0.550831\n",
       "4   0.706250  0.551444\n",
       "5   0.707031  0.551684\n",
       "6   0.705469  0.553730\n",
       "7   0.705469  0.552720\n",
       "8   0.706250  0.551711\n",
       "9   0.707813  0.553196\n",
       "10  0.944531  0.978487\n",
       "11  0.922309  0.971832\n",
       "12  0.931076  0.971416\n",
       "13  0.925608  0.971438\n",
       "14  0.931858  0.971736\n",
       "15  0.920747  0.972178\n",
       "16  0.944531  0.979028\n",
       "17  0.931076  0.978021\n",
       "18  0.932639  0.971466\n",
       "19  0.944531  0.979516"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# V = 10, B = 10\n",
    "df = pd.DataFrame(xval_dict[0]).iloc[:,:2] / 5\n",
    "for fold in range(1,5):\n",
    "    df += pd.DataFrame(xval_dict[fold]).iloc[:,:2] / 5\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d6d55c-291b-4d08-a249-9eca81cf4cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c5783b-5b86-465f-bdd3-22c4b1d49ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4162faed-5076-41ca-b75e-6447ba803634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accs</th>\n",
       "      <th>aucs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.532945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.700781</td>\n",
       "      <td>0.533767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.702344</td>\n",
       "      <td>0.534322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.700781</td>\n",
       "      <td>0.532731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.702344</td>\n",
       "      <td>0.533686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.701562</td>\n",
       "      <td>0.534217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.701562</td>\n",
       "      <td>0.533262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.700781</td>\n",
       "      <td>0.533476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.701562</td>\n",
       "      <td>0.533316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.708594</td>\n",
       "      <td>0.533023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.927951</td>\n",
       "      <td>0.968133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.927951</td>\n",
       "      <td>0.967839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.929514</td>\n",
       "      <td>0.967962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.927951</td>\n",
       "      <td>0.968084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.928733</td>\n",
       "      <td>0.968084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.930295</td>\n",
       "      <td>0.967863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.929514</td>\n",
       "      <td>0.967889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.928733</td>\n",
       "      <td>0.967790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.932639</td>\n",
       "      <td>0.968944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.933420</td>\n",
       "      <td>0.967227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accs      aucs\n",
       "0   0.703125  0.532945\n",
       "1   0.700781  0.533767\n",
       "2   0.702344  0.534322\n",
       "3   0.700781  0.532731\n",
       "4   0.702344  0.533686\n",
       "5   0.701562  0.534217\n",
       "6   0.701562  0.533262\n",
       "7   0.700781  0.533476\n",
       "8   0.701562  0.533316\n",
       "9   0.708594  0.533023\n",
       "10  0.927951  0.968133\n",
       "11  0.927951  0.967839\n",
       "12  0.929514  0.967962\n",
       "13  0.927951  0.968084\n",
       "14  0.928733  0.968084\n",
       "15  0.930295  0.967863\n",
       "16  0.929514  0.967889\n",
       "17  0.928733  0.967790\n",
       "18  0.932639  0.968944\n",
       "19  0.933420  0.967227"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# V = 10, B = 5\n",
    "df = pd.DataFrame(xval_dict[0]).iloc[:,:2] / 5\n",
    "for fold in range(1,5):\n",
    "    df += pd.DataFrame(xval_dict[fold]).iloc[:,:2] / 5\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6631daf8-d9d0-40e9-91de-df39a4c02b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accs</th>\n",
       "      <th>aucs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.810937</td>\n",
       "      <td>0.543453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.810937</td>\n",
       "      <td>0.544408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.814063</td>\n",
       "      <td>0.544170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.810937</td>\n",
       "      <td>0.544090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.545203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.811719</td>\n",
       "      <td>0.544225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.543878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.810937</td>\n",
       "      <td>0.543798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.813281</td>\n",
       "      <td>0.542712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.809375</td>\n",
       "      <td>0.544412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.933420</td>\n",
       "      <td>0.979075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.934201</td>\n",
       "      <td>0.979222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.933420</td>\n",
       "      <td>0.979247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.934983</td>\n",
       "      <td>0.979148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.933420</td>\n",
       "      <td>0.978903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.934983</td>\n",
       "      <td>0.979369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.933420</td>\n",
       "      <td>0.979662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.933420</td>\n",
       "      <td>0.978166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.934983</td>\n",
       "      <td>0.979222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.934201</td>\n",
       "      <td>0.978952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accs      aucs\n",
       "0   0.810937  0.543453\n",
       "1   0.810937  0.544408\n",
       "2   0.814063  0.544170\n",
       "3   0.810937  0.544090\n",
       "4   0.812500  0.545203\n",
       "5   0.811719  0.544225\n",
       "6   0.812500  0.543878\n",
       "7   0.810937  0.543798\n",
       "8   0.813281  0.542712\n",
       "9   0.809375  0.544412\n",
       "10  0.933420  0.979075\n",
       "11  0.934201  0.979222\n",
       "12  0.933420  0.979247\n",
       "13  0.934983  0.979148\n",
       "14  0.933420  0.978903\n",
       "15  0.934983  0.979369\n",
       "16  0.933420  0.979662\n",
       "17  0.933420  0.978166\n",
       "18  0.934983  0.979222\n",
       "19  0.934201  0.978952"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# V = 5, B = 5\n",
    "df = pd.DataFrame(xval_dict[0]).iloc[:,:2] / 5\n",
    "for fold in range(1,5):\n",
    "    df += pd.DataFrame(xval_dict[fold]).iloc[:,:2] / 5\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7592253d-0387-4539-b6dd-218a0edad4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accs</th>\n",
       "      <th>aucs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.683594</td>\n",
       "      <td>0.508111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.682813</td>\n",
       "      <td>0.507580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.684375</td>\n",
       "      <td>0.509303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.682813</td>\n",
       "      <td>0.509489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.507819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.688281</td>\n",
       "      <td>0.508720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.684375</td>\n",
       "      <td>0.508508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.681250</td>\n",
       "      <td>0.508349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.682813</td>\n",
       "      <td>0.507686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.685156</td>\n",
       "      <td>0.508110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.905122</td>\n",
       "      <td>0.964602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.901215</td>\n",
       "      <td>0.963525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.909809</td>\n",
       "      <td>0.964505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.909028</td>\n",
       "      <td>0.964235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.906684</td>\n",
       "      <td>0.964211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.911372</td>\n",
       "      <td>0.964554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.906684</td>\n",
       "      <td>0.964234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.910590</td>\n",
       "      <td>0.964161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.909028</td>\n",
       "      <td>0.964259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.909028</td>\n",
       "      <td>0.964308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accs      aucs\n",
       "0   0.683594  0.508111\n",
       "1   0.682813  0.507580\n",
       "2   0.684375  0.509303\n",
       "3   0.682813  0.509489\n",
       "4   0.687500  0.507819\n",
       "5   0.688281  0.508720\n",
       "6   0.684375  0.508508\n",
       "7   0.681250  0.508349\n",
       "8   0.682813  0.507686\n",
       "9   0.685156  0.508110\n",
       "10  0.905122  0.964602\n",
       "11  0.901215  0.963525\n",
       "12  0.909809  0.964505\n",
       "13  0.909028  0.964235\n",
       "14  0.906684  0.964211\n",
       "15  0.911372  0.964554\n",
       "16  0.906684  0.964234\n",
       "17  0.910590  0.964161\n",
       "18  0.909028  0.964259\n",
       "19  0.909028  0.964308"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# V = 2, B = 10\n",
    "df = pd.DataFrame(xval_dict[0]).iloc[:,:2] / 5\n",
    "for fold in range(1,5):\n",
    "    df += pd.DataFrame(xval_dict[fold]).iloc[:,:2] / 5\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3b8923fb-392f-4d49-a4c3-cc9c9179e1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accs</th>\n",
       "      <th>aucs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.696875</td>\n",
       "      <td>0.528527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.696875</td>\n",
       "      <td>0.528421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.696875</td>\n",
       "      <td>0.528554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.696875</td>\n",
       "      <td>0.528554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.696875</td>\n",
       "      <td>0.528474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.696875</td>\n",
       "      <td>0.528633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.694531</td>\n",
       "      <td>0.527563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.696875</td>\n",
       "      <td>0.528528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.696875</td>\n",
       "      <td>0.528580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.696875</td>\n",
       "      <td>0.528421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.975888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.975789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.932813</td>\n",
       "      <td>0.975765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.976354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.976010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.938281</td>\n",
       "      <td>0.976157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.975986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.976059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.976353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.926389</td>\n",
       "      <td>0.976035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accs      aucs\n",
       "0   0.696875  0.528527\n",
       "1   0.696875  0.528421\n",
       "2   0.696875  0.528554\n",
       "3   0.696875  0.528554\n",
       "4   0.696875  0.528474\n",
       "5   0.696875  0.528633\n",
       "6   0.694531  0.527563\n",
       "7   0.696875  0.528528\n",
       "8   0.696875  0.528580\n",
       "9   0.696875  0.528421\n",
       "10  0.937500  0.975888\n",
       "11  0.937500  0.975789\n",
       "12  0.932813  0.975765\n",
       "13  0.937500  0.976354\n",
       "14  0.937500  0.976010\n",
       "15  0.938281  0.976157\n",
       "16  0.937500  0.975986\n",
       "17  0.937500  0.976059\n",
       "18  0.934375  0.976353\n",
       "19  0.926389  0.976035"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# V = 2, B = 5\n",
    "df = pd.DataFrame(xval_dict[0]).iloc[:,:2] / 5\n",
    "for fold in range(1,5):\n",
    "    df += pd.DataFrame(xval_dict[fold]).iloc[:,:2] / 5\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0fba00da-dadf-4529-9835-3c249499a02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accs</th>\n",
       "      <th>aucs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.682813</td>\n",
       "      <td>0.502315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.682813</td>\n",
       "      <td>0.502288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.682813</td>\n",
       "      <td>0.501693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.682031</td>\n",
       "      <td>0.502103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.678906</td>\n",
       "      <td>0.501462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.681250</td>\n",
       "      <td>0.500805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.681250</td>\n",
       "      <td>0.499776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.681250</td>\n",
       "      <td>0.501623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.678125</td>\n",
       "      <td>0.498670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.684375</td>\n",
       "      <td>0.502397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.857465</td>\n",
       "      <td>0.907756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.858247</td>\n",
       "      <td>0.895942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.855903</td>\n",
       "      <td>0.900966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.843229</td>\n",
       "      <td>0.894766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.859028</td>\n",
       "      <td>0.894496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.859809</td>\n",
       "      <td>0.901482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.858247</td>\n",
       "      <td>0.895697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.858247</td>\n",
       "      <td>0.895109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.855903</td>\n",
       "      <td>0.899861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.845573</td>\n",
       "      <td>0.903478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accs      aucs\n",
       "0   0.682813  0.502315\n",
       "1   0.682813  0.502288\n",
       "2   0.682813  0.501693\n",
       "3   0.682031  0.502103\n",
       "4   0.678906  0.501462\n",
       "5   0.681250  0.500805\n",
       "6   0.681250  0.499776\n",
       "7   0.681250  0.501623\n",
       "8   0.678125  0.498670\n",
       "9   0.684375  0.502397\n",
       "10  0.857465  0.907756\n",
       "11  0.858247  0.895942\n",
       "12  0.855903  0.900966\n",
       "13  0.843229  0.894766\n",
       "14  0.859028  0.894496\n",
       "15  0.859809  0.901482\n",
       "16  0.858247  0.895697\n",
       "17  0.858247  0.895109\n",
       "18  0.855903  0.899861\n",
       "19  0.845573  0.903478"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# V = 2, B = 2\n",
    "df = pd.DataFrame(xval_dict[0]).iloc[:,:2] / 5\n",
    "for fold in range(1,5):\n",
    "    df += pd.DataFrame(xval_dict[fold]).iloc[:,:2] / 5\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5b05e6-126e-4d47-8109-0e72378b2dae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23fdcf2-334c-4292-9eed-7e9ed0c6daaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b940844-9dc0-47de-a80b-0381167ccfef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
