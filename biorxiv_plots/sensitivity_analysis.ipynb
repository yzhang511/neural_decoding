{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "953f7214-5b35-47c3-9aa3-16af600219a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.stats import pointbiserialr\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    roc_auc_score, \n",
    "    roc_curve, \n",
    ")\n",
    "\n",
    "from side_info_decoding.utils import (\n",
    "    set_seed, \n",
    "    load_data_from_pids, \n",
    "    sliding_window_over_trials\n",
    ")\n",
    "from side_info_decoding.reduced_rank import (\n",
    "    Reduced_Rank_Model, \n",
    "    train_single_task, \n",
    "    model_eval,\n",
    "    Multi_Task_Reduced_Rank_Model,\n",
    "    train_multi_task\n",
    ")\n",
    "\n",
    "import pymc3 as pm\n",
    "from hmmlearn import vhmm\n",
    "from side_info_decoding.bmm_hmm import (\n",
    "    BetaProcess, Constrained_BMM_HMM, posterior_inference\n",
    ")\n",
    "from side_info_decoding.viz import plot_multi_session_hmm_results, plot_bmm_hmm_results\n",
    "\n",
    "seed = 666\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1a2d3b1-bdd8-423a-93f1-b206be47bd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rc(\"figure\", dpi=200)\n",
    "SMALL_SIZE = 10\n",
    "BIGGER_SIZE = 10\n",
    "plt.rc('font', size=BIGGER_SIZE)\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)\n",
    "plt.rc('axes', labelsize=BIGGER_SIZE)\n",
    "plt.rc('axes', linewidth=1)\n",
    "plt.rc('xtick', labelsize=BIGGER_SIZE)\n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)\n",
    "plt.rc('figure', titlesize=1)\n",
    "plt.rcParams['xtick.major.size'] = 3\n",
    "plt.rcParams['xtick.minor.size'] = 3\n",
    "plt.rcParams['ytick.major.size'] = 3\n",
    "plt.rcParams['ytick.minor.size'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235cd875-0f6a-4610-b9fb-6f8fbf6ea455",
   "metadata": {},
   "source": [
    "#### RRR vs. multi-session RRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0abf328c-8138-439e-a35e-79d0a1820433",
   "metadata": {},
   "outputs": [],
   "source": [
    "pids = [\n",
    "    \"dab512bd-a02d-4c1f-8dbc-9155a163efc0\",\n",
    "    \"febb430e-2d50-4f83-87a0-b5ffbb9a4943\",\n",
    "    \"6fc4d73c-2071-43ec-a756-c6c6d8322c8b\",\n",
    "    \"523f8301-4f56-4faf-ab33-a9ff11331118\",\n",
    "    \"143dd7cf-6a47-47a1-906d-927ad7fe9117\",\n",
    "    '1a60a6e1-da99-4d4e-a734-39b1d4544fad',\n",
    "    '0b8ea3ec-e75b-41a1-9442-64f5fbc11a5a',\n",
    "    '1e176f17-d00f-49bb-87ff-26d237b525f1',\n",
    "    '16799c7a-e395-435d-a4c4-a678007e1550',\n",
    "     'ad714133-1e03-4d3a-8427-33fc483daf1a',\n",
    "     '31f3e083-a324-4b88-b0a4-7788ec37b191',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cbb0da-23a7-4c09-a684-176d374d9e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dict, Y_dict = load_data_from_pids(\n",
    "    pids,\n",
    "    brain_region=\"all\",\n",
    "    behavior=\"choice\",\n",
    "    data_type=\"all_ks\",\n",
    "    t_before=0.5,\n",
    "    t_after=1.5,\n",
    "    n_t_bins=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be7cde2c-9b02-4cdf-9f11-07a3b4e933d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = [2, 5, 10, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8dde446-bc32-4e46-9eb4-3cd770703e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training fold 1 on 11 sessions ..\n",
      "Epoch [100/1000], Loss: 21.68406470180929\n",
      "Epoch [200/1000], Loss: 1.0371153225414398\n",
      "Epoch [300/1000], Loss: 0.37614249174877545\n",
      "Epoch [400/1000], Loss: 0.2145229218276752\n",
      "Epoch [500/1000], Loss: 0.18490575001629478\n",
      "Epoch [600/1000], Loss: 0.18095661123248744\n",
      "Epoch [700/1000], Loss: 0.1811074051736613\n",
      "Epoch [800/1000], Loss: 0.18071352847883032\n",
      "Epoch [900/1000], Loss: 0.18237798755952406\n",
      "Epoch [1000/1000], Loss: 0.18397621909760975\n",
      "task 0 train accuracy: 0.993 auc: 1.000\n",
      "task 0 test accuracy: 0.878 auc: 0.941\n",
      "task 1 train accuracy: 0.993 auc: 1.000\n",
      "task 1 test accuracy: 0.957 auc: 0.996\n",
      "task 2 train accuracy: 0.959 auc: 0.988\n",
      "task 2 test accuracy: 0.814 auc: 0.902\n",
      "task 3 train accuracy: 0.994 auc: 0.999\n",
      "task 3 test accuracy: 0.900 auc: 0.971\n",
      "task 4 train accuracy: 0.926 auc: 0.977\n",
      "task 4 test accuracy: 0.785 auc: 0.846\n",
      "task 5 train accuracy: 0.992 auc: 1.000\n",
      "task 5 test accuracy: 0.933 auc: 0.976\n",
      "task 6 train accuracy: 0.993 auc: 1.000\n",
      "task 6 test accuracy: 0.905 auc: 0.977\n",
      "task 7 train accuracy: 0.970 auc: 0.995\n",
      "task 7 test accuracy: 0.914 auc: 0.972\n",
      "task 8 train accuracy: 0.985 auc: 0.999\n",
      "task 8 test accuracy: 0.917 auc: 0.975\n",
      "task 9 train accuracy: 0.985 auc: 0.999\n",
      "task 9 test accuracy: 0.932 auc: 0.987\n",
      "task 10 train accuracy: 0.967 auc: 0.995\n",
      "task 10 test accuracy: 0.955 auc: 0.996\n",
      "start training fold 2 on 11 sessions ..\n",
      "Epoch [100/1000], Loss: 23.58287441848379\n",
      "Epoch [200/1000], Loss: 1.4576460875455417\n",
      "Epoch [300/1000], Loss: 0.41148391211251006\n",
      "Epoch [400/1000], Loss: 0.22786408151405402\n",
      "Epoch [500/1000], Loss: 0.18933350930996837\n",
      "Epoch [600/1000], Loss: 0.18173408052719012\n",
      "Epoch [700/1000], Loss: 0.18008209590908153\n",
      "Epoch [800/1000], Loss: 0.17969656987576776\n",
      "Epoch [900/1000], Loss: 0.18009145498399712\n",
      "Epoch [1000/1000], Loss: 0.17994129678778065\n",
      "task 0 train accuracy: 0.986 auc: 1.000\n",
      "task 0 test accuracy: 0.892 auc: 0.962\n",
      "task 1 train accuracy: 0.993 auc: 0.999\n",
      "task 1 test accuracy: 0.957 auc: 0.994\n",
      "task 2 train accuracy: 0.971 auc: 0.992\n",
      "task 2 test accuracy: 0.791 auc: 0.918\n",
      "task 3 train accuracy: 0.987 auc: 1.000\n",
      "task 3 test accuracy: 0.900 auc: 0.974\n",
      "task 4 train accuracy: 0.924 auc: 0.981\n",
      "task 4 test accuracy: 0.702 auc: 0.800\n",
      "task 5 train accuracy: 0.986 auc: 0.999\n",
      "task 5 test accuracy: 0.989 auc: 0.982\n",
      "task 6 train accuracy: 0.990 auc: 1.000\n",
      "task 6 test accuracy: 0.959 auc: 0.996\n",
      "task 7 train accuracy: 0.976 auc: 0.997\n",
      "task 7 test accuracy: 0.828 auc: 0.888\n",
      "task 8 train accuracy: 0.982 auc: 1.000\n",
      "task 8 test accuracy: 0.964 auc: 0.994\n",
      "task 9 train accuracy: 0.985 auc: 0.999\n",
      "task 9 test accuracy: 0.932 auc: 0.981\n",
      "task 10 train accuracy: 0.966 auc: 0.996\n",
      "task 10 test accuracy: 0.915 auc: 0.977\n",
      "start training fold 3 on 11 sessions ..\n",
      "Epoch [100/1000], Loss: 22.35329498965156\n",
      "Epoch [200/1000], Loss: 1.0955006983702467\n",
      "Epoch [300/1000], Loss: 0.422332291231228\n",
      "Epoch [400/1000], Loss: 0.22942974310725617\n",
      "Epoch [500/1000], Loss: 0.19250572395133875\n",
      "Epoch [600/1000], Loss: 0.18221825060464633\n",
      "Epoch [700/1000], Loss: 0.18174110710626123\n",
      "Epoch [800/1000], Loss: 0.1805849379858866\n",
      "Epoch [900/1000], Loss: 0.18041143786027433\n",
      "Epoch [1000/1000], Loss: 0.18072884380108606\n",
      "task 0 train accuracy: 0.986 auc: 0.999\n",
      "task 0 test accuracy: 0.890 auc: 0.953\n",
      "task 1 train accuracy: 0.989 auc: 1.000\n",
      "task 1 test accuracy: 0.957 auc: 1.000\n",
      "task 2 train accuracy: 0.953 auc: 0.989\n",
      "task 2 test accuracy: 0.884 auc: 0.967\n",
      "task 3 train accuracy: 0.994 auc: 1.000\n",
      "task 3 test accuracy: 0.873 auc: 0.956\n",
      "task 4 train accuracy: 0.905 auc: 0.974\n",
      "task 4 test accuracy: 0.711 auc: 0.802\n",
      "task 5 train accuracy: 0.989 auc: 0.999\n",
      "task 5 test accuracy: 0.978 auc: 0.990\n",
      "task 6 train accuracy: 0.990 auc: 1.000\n",
      "task 6 test accuracy: 0.959 auc: 0.986\n",
      "task 7 train accuracy: 0.976 auc: 0.998\n",
      "task 7 test accuracy: 0.839 auc: 0.922\n",
      "task 8 train accuracy: 0.979 auc: 1.000\n",
      "task 8 test accuracy: 0.892 auc: 0.978\n",
      "task 9 train accuracy: 0.991 auc: 0.999\n",
      "task 9 test accuracy: 0.915 auc: 0.961\n",
      "task 10 train accuracy: 0.971 auc: 0.996\n",
      "task 10 test accuracy: 0.935 auc: 0.978\n",
      "start training fold 4 on 11 sessions ..\n",
      "Epoch [100/1000], Loss: 23.06093450855875\n",
      "Epoch [200/1000], Loss: 0.9103898513696923\n",
      "Epoch [300/1000], Loss: 0.46909446456126014\n",
      "Epoch [400/1000], Loss: 0.21596795871705893\n",
      "Epoch [500/1000], Loss: 0.180140918692269\n",
      "Epoch [600/1000], Loss: 0.17454236339205714\n",
      "Epoch [700/1000], Loss: 0.17410053444218582\n",
      "Epoch [800/1000], Loss: 0.17384884587559976\n",
      "Epoch [900/1000], Loss: 0.17763474816892746\n",
      "Epoch [1000/1000], Loss: 0.17567741582796853\n",
      "task 0 train accuracy: 0.983 auc: 0.999\n",
      "task 0 test accuracy: 0.904 auc: 0.964\n",
      "task 1 train accuracy: 0.993 auc: 1.000\n",
      "task 1 test accuracy: 0.943 auc: 0.976\n",
      "task 2 train accuracy: 0.974 auc: 0.992\n",
      "task 2 test accuracy: 0.812 auc: 0.895\n",
      "task 3 train accuracy: 0.991 auc: 0.999\n",
      "task 3 test accuracy: 0.911 auc: 0.975\n",
      "task 4 train accuracy: 0.907 auc: 0.975\n",
      "task 4 test accuracy: 0.702 auc: 0.765\n",
      "task 5 train accuracy: 0.992 auc: 1.000\n",
      "task 5 test accuracy: 0.944 auc: 0.978\n",
      "task 6 train accuracy: 0.993 auc: 1.000\n",
      "task 6 test accuracy: 0.973 auc: 0.966\n",
      "task 7 train accuracy: 0.976 auc: 0.998\n",
      "task 7 test accuracy: 0.793 auc: 0.842\n",
      "task 8 train accuracy: 0.988 auc: 1.000\n",
      "task 8 test accuracy: 0.952 auc: 0.972\n",
      "task 9 train accuracy: 0.983 auc: 0.999\n",
      "task 9 test accuracy: 0.897 auc: 0.969\n",
      "task 10 train accuracy: 0.976 auc: 0.997\n",
      "task 10 test accuracy: 0.882 auc: 0.930\n",
      "start training fold 5 on 11 sessions ..\n",
      "Epoch [100/1000], Loss: 25.45686342312198\n",
      "Epoch [200/1000], Loss: 1.6517173185074618\n",
      "Epoch [300/1000], Loss: 0.32731160180113333\n",
      "Epoch [400/1000], Loss: 0.2132133779575215\n",
      "Epoch [500/1000], Loss: 0.1821383736081433\n",
      "Epoch [600/1000], Loss: 0.17729455600464247\n",
      "Epoch [700/1000], Loss: 0.1774839785817873\n",
      "Epoch [800/1000], Loss: 0.18306885669388395\n",
      "Epoch [900/1000], Loss: 0.1771919240510911\n",
      "Epoch [1000/1000], Loss: 0.1770207549038535\n",
      "task 0 train accuracy: 0.986 auc: 0.999\n",
      "task 0 test accuracy: 0.863 auc: 0.936\n",
      "task 1 train accuracy: 0.993 auc: 1.000\n",
      "task 1 test accuracy: 0.914 auc: 0.989\n",
      "task 2 train accuracy: 0.965 auc: 0.994\n",
      "task 2 test accuracy: 0.894 auc: 0.912\n",
      "task 3 train accuracy: 0.991 auc: 1.000\n",
      "task 3 test accuracy: 0.873 auc: 0.959\n",
      "task 4 train accuracy: 0.913 auc: 0.979\n",
      "task 4 test accuracy: 0.769 auc: 0.829\n",
      "task 5 train accuracy: 0.989 auc: 0.999\n",
      "task 5 test accuracy: 0.900 auc: 0.985\n",
      "task 6 train accuracy: 0.993 auc: 1.000\n",
      "task 6 test accuracy: 0.849 auc: 0.969\n",
      "task 7 train accuracy: 0.957 auc: 0.995\n",
      "task 7 test accuracy: 0.826 auc: 0.950\n",
      "task 8 train accuracy: 0.988 auc: 1.000\n",
      "task 8 test accuracy: 0.880 auc: 0.950\n",
      "task 9 train accuracy: 0.991 auc: 1.000\n",
      "task 9 test accuracy: 0.931 auc: 0.953\n",
      "task 10 train accuracy: 0.971 auc: 0.996\n",
      "task 10 test accuracy: 0.908 auc: 0.981\n"
     ]
    }
   ],
   "source": [
    "R = 5 # rank\n",
    "d = 0 # half window size\n",
    "n_epochs = 1000\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "n_units = []\n",
    "train_X_dict, test_X_dict, train_Y_dict, test_Y_dict = {}, {}, {}, {}\n",
    "for pid in pids:\n",
    "    X, Y = X_dict[pid], Y_dict[pid]\n",
    "    K, C, T = X.shape\n",
    "    n_units.append(C)\n",
    "    X = sliding_window_over_trials(X, half_window_size=d)\n",
    "    Y = sliding_window_over_trials(Y, half_window_size=d)\n",
    "    X, Y = torch.tensor(X), torch.tensor(Y)\n",
    "    train_X_dict.update({pid: [X[train] for train, _ in skf.split(X, Y)]})\n",
    "    test_X_dict.update({pid: [X[test] for _, test in skf.split(X, Y)]})\n",
    "    train_Y_dict.update({pid: [Y[train] for train, _ in skf.split(X, Y)]})\n",
    "    test_Y_dict.update({pid: [Y[test] for _, test in skf.split(X, Y)]})\n",
    "\n",
    "for fold_idx in range(5):\n",
    "    \n",
    "    print(f\"start training fold {fold_idx+1} on {len(pids)} sessions ..\")\n",
    "    train_X_lst = [train_X_dict[pid][fold_idx] for pid in pids]\n",
    "    test_X_lst = [test_X_dict[pid][fold_idx] for pid in pids]\n",
    "    train_Y_lst = [train_Y_dict[pid][fold_idx] for pid in pids]\n",
    "    test_Y_lst = [test_Y_dict[pid][fold_idx] for pid in pids]\n",
    "    \n",
    "    multi_task_rrm = Multi_Task_Reduced_Rank_Model(\n",
    "        n_tasks=len(pids),\n",
    "        n_units=n_units, \n",
    "        n_t_bins=T, \n",
    "        rank=R, \n",
    "        half_window_size=d\n",
    "    )\n",
    "\n",
    "    # training\n",
    "    multi_task_rrm, train_losses = train_multi_task(\n",
    "        model=multi_task_rrm,\n",
    "        train_dataset=(train_X_lst, train_Y_lst),\n",
    "        test_dataset=(test_X_lst, test_Y_lst),\n",
    "        loss_function=torch.nn.BCELoss(),\n",
    "        learning_rate=1e-2,\n",
    "        weight_decay=1e-1,\n",
    "        n_epochs=n_epochs,\n",
    "    )\n",
    "\n",
    "    # eval\n",
    "    test_U, test_V, test_metrics, _ = model_eval(\n",
    "        multi_task_rrm, \n",
    "        train_dataset=(train_X_lst, train_Y_lst),\n",
    "        test_dataset=(test_X_lst, test_Y_lst),\n",
    "        behavior=\"choice\"\n",
    "    )\n",
    "    \n",
    "    save_path = Path(\"./sensitivity_rank\") / \"choice\" / f\"rank_{R}\"\n",
    "    os.makedirs(save_path, exist_ok=True) \n",
    "    np.save(save_path/f\"fold_{fold_idx}.npy\", test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0137cbb7-144c-4a2e-9462-9a3a0a566f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906127af-d459-42de-95f2-a222a1dcf4dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
