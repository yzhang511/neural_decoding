{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "953f7214-5b35-47c3-9aa3-16af600219a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.stats import pointbiserialr\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    roc_auc_score, \n",
    "    roc_curve, \n",
    ")\n",
    "\n",
    "from side_info_decoding.utils import (\n",
    "    set_seed, \n",
    "    load_data_from_pids, \n",
    "    sliding_window_over_trials\n",
    ")\n",
    "from side_info_decoding.reduced_rank import (\n",
    "    Reduced_Rank_Model, \n",
    "    train_single_task, \n",
    "    model_eval,\n",
    "    Multi_Task_Reduced_Rank_Model,\n",
    "    train_multi_task,\n",
    ")\n",
    "\n",
    "import pymc3 as pm\n",
    "from hmmlearn import vhmm\n",
    "from side_info_decoding.bmm_hmm import (\n",
    "    BetaProcess, Constrained_BMM_HMM, posterior_inference\n",
    ")\n",
    "from side_info_decoding.viz import plot_multi_session_hmm_results, plot_bmm_hmm_results\n",
    "\n",
    "seed = 666\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75527cbd-a94f-44b4-a14d-c4d933e7513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReducedRankRegression(torch.nn.Module):    \n",
    "    def __init__(self, n_c, n_t, n_r):\n",
    "        super(ReducedRankRegression, self).__init__()\n",
    "        self.U = torch.nn.Parameter(torch.randn(n_c, n_r))\n",
    "        self.V = torch.nn.Parameter(torch.randn(n_r, n_t))\n",
    "        self.b = torch.nn.Parameter(torch.randn(1,))\n",
    "        self.double()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.beta = self.U @ self.V\n",
    "        out = torch.einsum(\"ct,kct->kt\", self.beta, x)\n",
    "        out += self.b\n",
    "        return out\n",
    "    \n",
    "def train_rrr(\n",
    "    X, \n",
    "    Y, \n",
    "    train,\n",
    "    test,\n",
    "    n_r = 10,\n",
    "    learning_rate=1e-3,\n",
    "    n_epochs=10000,\n",
    "    ):\n",
    "    \n",
    "    _, n_c, n_t = X.shape\n",
    "    rrr = ReducedRankRegression(n_c, n_t, n_r)\n",
    "    optimizer = torch.optim.Adam(rrr.parameters(), lr=learning_rate, weight_decay=1e-3)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    train_x, test_x = X[train], X[test]\n",
    "    train_y, test_y = Y[train], Y[test]\n",
    "    \n",
    "    losses = []\n",
    "    for epoch in tqdm(range(n_epochs), desc=\"Train RRR:\"):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = rrr(train_x)\n",
    "        loss = criterion(y_pred, train_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    return rrr, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d888b9dd-e4ab-494f-ae0d-bd6b6e5ccb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_bin_wise_metrics(y_true, y_pred):\n",
    "    r2 = r2_score(y_true.flatten(), y_pred.flatten())\n",
    "    adj_r2 = explained_variance_score(y_true, y_pred)\n",
    "    return r2, adj_r2\n",
    "\n",
    "def sliding_window_over_time(data, window_size=10):\n",
    "    \n",
    "    if len(data.shape) == 3:\n",
    "        n_trials, n_units, n_t_bins = data.shape\n",
    "        data_window = np.zeros((\n",
    "            n_trials, n_units, n_t_bins - window_size + 1, window_size\n",
    "        ))\n",
    "        for t in range(window_size-1, n_t_bins):\n",
    "            tmp_window = np.zeros((n_trials, n_units, window_size))\n",
    "            for d in range(window_size):\n",
    "                  tmp_window[:,:,d] = data[:,:,t - d]\n",
    "            data_window[:,:,t-window_size] = tmp_window\n",
    "    else:\n",
    "        n_trials, n_t_bins = data.shape\n",
    "        data_window = np.zeros((n_trials, n_t_bins - window_size + 1))\n",
    "        for t in range(window_size-1, n_t_bins):\n",
    "            data_window[:,t-window_size] = data[:,t]\n",
    "    return data_window\n",
    "\n",
    "def causal_decoder(train_X, train_Y, test_X, test_Y, verbose=True):\n",
    "    penalty = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10]\n",
    "    \n",
    "    train_K, C, T, L = train_X.shape\n",
    "    test_K, _, _, _ = test_X.shape\n",
    "    \n",
    "    train_X = train_X.transpose(0,1,-1,2).reshape(train_K, C*L, T).transpose(0,-1,1).reshape((-1, C*L))\n",
    "    test_X = test_X.transpose(0,1,-1,2).reshape(test_K, C*L, T).transpose(0,-1,1).reshape((-1, C*L))\n",
    "    train_Y = train_Y.reshape((-1))\n",
    "    test_Y = test_Y.reshape((-1))\n",
    "    \n",
    "    decoder = GridSearchCV(Ridge(), {\"alpha\": penalty})\n",
    "    decoder.fit(train_X, train_Y)\n",
    "    pred_Y = decoder.predict(test_X)\n",
    "    test_Y = test_Y.reshape(test_K, T)\n",
    "    pred_Y = pred_Y.reshape(test_K, T)\n",
    "    \n",
    "    r2, adj_r2 = time_bin_wise_metrics(test_Y, pred_Y)\n",
    "    if verbose:\n",
    "        print(f\"r2: {r2:.3f} adj-r2: {adj_r2:.3f}\")\n",
    "    \n",
    "    return pred_Y, [r2, adj_r2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1a2d3b1-bdd8-423a-93f1-b206be47bd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rc(\"figure\", dpi=200)\n",
    "SMALL_SIZE = 10\n",
    "BIGGER_SIZE = 10\n",
    "plt.rc('font', size=BIGGER_SIZE)\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)\n",
    "plt.rc('axes', labelsize=BIGGER_SIZE)\n",
    "plt.rc('axes', linewidth=1)\n",
    "plt.rc('xtick', labelsize=BIGGER_SIZE)\n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)\n",
    "plt.rc('figure', titlesize=1)\n",
    "plt.rcParams['xtick.major.size'] = 3\n",
    "plt.rcParams['xtick.minor.size'] = 3\n",
    "plt.rcParams['ytick.major.size'] = 3\n",
    "plt.rcParams['ytick.minor.size'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235cd875-0f6a-4610-b9fb-6f8fbf6ea455",
   "metadata": {},
   "source": [
    "#### RRR vs. multi-session RRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0abf328c-8138-439e-a35e-79d0a1820433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pids = [\n",
    "#     \"dab512bd-a02d-4c1f-8dbc-9155a163efc0\",\n",
    "#     \"febb430e-2d50-4f83-87a0-b5ffbb9a4943\",\n",
    "#     \"6fc4d73c-2071-43ec-a756-c6c6d8322c8b\",\n",
    "#     \"523f8301-4f56-4faf-ab33-a9ff11331118\",\n",
    "#     \"143dd7cf-6a47-47a1-906d-927ad7fe9117\",\n",
    "#     '1a60a6e1-da99-4d4e-a734-39b1d4544fad',\n",
    "#     '0b8ea3ec-e75b-41a1-9442-64f5fbc11a5a',\n",
    "#     '1e176f17-d00f-49bb-87ff-26d237b525f1',\n",
    "#     '16799c7a-e395-435d-a4c4-a678007e1550',\n",
    "#      'ad714133-1e03-4d3a-8427-33fc483daf1a',\n",
    "#      '31f3e083-a324-4b88-b0a4-7788ec37b191',\n",
    "# ]\n",
    "\n",
    "pids = [\n",
    "    \"6fc4d73c-2071-43ec-a756-c6c6d8322c8b\",\n",
    "    \"1a60a6e1-da99-4d4e-a734-39b1d4544fad\",\n",
    "    \"dab512bd-a02d-4c1f-8dbc-9155a163efc0\",\n",
    "    \"febb430e-2d50-4f83-87a0-b5ffbb9a4943\",\n",
    "    \"84bb830f-b9ff-4e6b-9296-f458fb41d160\",\n",
    "    \"523f8301-4f56-4faf-ab33-a9ff11331118\",\n",
    "    \"143dd7cf-6a47-47a1-906d-927ad7fe9117\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43cbb0da-23a7-4c09-a684-176d374d9e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling data from ibl database ..\n",
      "eid: dac3a4c1-b666-4de0-87e8-8c514483cacf\n",
      "pid: 6fc4d73c-2071-43ec-a756-c6c6d8322c8b\n",
      "number of trials found: 428\n",
      "found 428 trials from 281.82 to 3112.92 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute spike count: 100%|███████████████████| 428/428 [00:02<00:00, 197.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling data from ibl database ..\n",
      "eid: 51e53aff-1d5d-4182-a684-aba783d50ae5\n",
      "pid: 1a60a6e1-da99-4d4e-a734-39b1d4544fad\n",
      "number of trials found: 450\n",
      "found 450 trials from 20.56 to 2612.19 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute spike count: 100%|████████████████████| 450/450 [00:06<00:00, 65.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling data from ibl database ..\n",
      "eid: d23a44ef-1402-4ed7-97f5-47e9a7a504d9\n",
      "pid: dab512bd-a02d-4c1f-8dbc-9155a163efc0\n",
      "number of trials found: 367\n",
      "found 367 trials from 17.56 to 2310.24 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute spike count: 100%|████████████████████| 367/367 [00:04<00:00, 83.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling data from ibl database ..\n",
      "eid: db4df448-e449-4a6f-a0e7-288711e7a75a\n",
      "pid: febb430e-2d50-4f83-87a0-b5ffbb9a4943\n",
      "number of trials found: 350\n",
      "found 350 trials from 22.21 to 2393.54 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute spike count: 100%|███████████████████| 350/350 [00:02<00:00, 145.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling data from ibl database ..\n",
      "eid: c7248e09-8c0d-40f2-9eb4-700a8973d8c8\n",
      "pid: 84bb830f-b9ff-4e6b-9296-f458fb41d160\n",
      "number of trials found: 688\n",
      "found 688 trials from 17.65 to 3851.03 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute spike count: 100%|████████████████████| 688/688 [00:31<00:00, 21.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling data from ibl database ..\n",
      "eid: 88224abb-5746-431f-9c17-17d7ef806e6a\n",
      "pid: 523f8301-4f56-4faf-ab33-a9ff11331118\n",
      "number of trials found: 397\n",
      "found 397 trials from 37.78 to 2183.45 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute spike count: 100%|████████████████████| 397/397 [00:05<00:00, 78.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling data from ibl database ..\n",
      "eid: 3638d102-e8b6-4230-8742-e548cd87a949\n",
      "pid: 143dd7cf-6a47-47a1-906d-927ad7fe9117\n",
      "number of trials found: 605\n",
      "found 605 trials from 32.91 to 4786.28 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute spike count: 100%|███████████████████| 605/605 [00:03<00:00, 155.62it/s]\n"
     ]
    }
   ],
   "source": [
    "X_dict, Y_dict = load_data_from_pids(\n",
    "    pids,\n",
    "    brain_region=\"all\",\n",
    "    behavior=\"prior\",\n",
    "    data_type=\"all_ks\",\n",
    "    n_t_bins=30,\n",
    "    prior_path = \"/mnt/3TB/yizi/Downloads/ONE/openalyx.internationalbrainlab.org/paper_repro_ephys_data/figure9_10/priors/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be7cde2c-9b02-4cdf-9f11-07a3b4e933d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = [2, 5, 10, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dde446-bc32-4e46-9eb4-3cd770703e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training fold 1 on 7 sessions ..\n"
     ]
    }
   ],
   "source": [
    "d = 3 # half window size\n",
    "n_epochs = 700\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "skf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "n_units = []\n",
    "train_X_dict, test_X_dict, train_Y_dict, test_Y_dict = {}, {}, {}, {}\n",
    "for pid in pids:\n",
    "    X, Y = X_dict[pid], Y_dict[pid]\n",
    "    K, C, T = X.shape\n",
    "    n_units.append(C)\n",
    "    X = sliding_window_over_trials(X, half_window_size=d)\n",
    "    Y = sliding_window_over_trials(Y, half_window_size=d)\n",
    "    X, Y = torch.tensor(X), torch.tensor(Y)\n",
    "    train_X_dict.update({pid: [X[train] for train, _ in skf.split(X, Y)]})\n",
    "    test_X_dict.update({pid: [X[test] for _, test in skf.split(X, Y)]})\n",
    "    train_Y_dict.update({pid: [Y[train] for train, _ in skf.split(X, Y)]})\n",
    "    test_Y_dict.update({pid: [Y[test] for _, test in skf.split(X, Y)]})\n",
    "\n",
    "for R in [10, 15]:\n",
    "    for fold_idx in range(5):\n",
    "\n",
    "        print(f\"start training fold {fold_idx+1} on {len(pids)} sessions ..\")\n",
    "        train_X_lst = [train_X_dict[pid][fold_idx] for pid in pids]\n",
    "        test_X_lst = [test_X_dict[pid][fold_idx] for pid in pids]\n",
    "        train_Y_lst = [train_Y_dict[pid][fold_idx] for pid in pids]\n",
    "        test_Y_lst = [test_Y_dict[pid][fold_idx] for pid in pids]\n",
    "\n",
    "        multi_task_rrm = Multi_Task_Reduced_Rank_Model(\n",
    "            n_tasks=len(pids),\n",
    "            n_units=n_units, \n",
    "            n_t_bins=T, \n",
    "            rank=R, \n",
    "            half_window_size=d\n",
    "        )\n",
    "\n",
    "        # training\n",
    "        multi_task_rrm, train_losses = train_multi_task(\n",
    "            model=multi_task_rrm,\n",
    "            train_dataset=(train_X_lst, train_Y_lst),\n",
    "            test_dataset=(test_X_lst, test_Y_lst),\n",
    "            # loss_function=torch.nn.BCELoss(),\n",
    "            loss_function=torch.nn.MSELoss(),\n",
    "            learning_rate=1e-2,\n",
    "            weight_decay=1e-1,\n",
    "            n_epochs=n_epochs,\n",
    "        )\n",
    "\n",
    "        # eval\n",
    "        test_U, test_V, test_metrics, _ = model_eval(\n",
    "            multi_task_rrm, \n",
    "            train_dataset=(train_X_lst, train_Y_lst),\n",
    "            test_dataset=(test_X_lst, test_Y_lst),\n",
    "            behavior=\"prior\"\n",
    "        )\n",
    "\n",
    "        save_path = Path(\"./sensitivity_rank\") / \"prior\" / f\"rank_{R}\"\n",
    "        os.makedirs(save_path, exist_ok=True) \n",
    "        np.save(save_path/f\"fold_{fold_idx}.npy\", test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c5a3a4e-7242-4d1b-a2e4-d2014471902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = [2, 5, 10, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4355881f-458a-447b-8470-5d8300c330b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score, explained_variance_score\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb19798b-2e19-41bd-8280-f1b14652818a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling data from ibl database ..\n",
      "eid: db4df448-e449-4a6f-a0e7-288711e7a75a\n",
      "pid: febb430e-2d50-4f83-87a0-b5ffbb9a4943\n",
      "number of trials found: 350\n",
      "found 350 trials from 34.74 to 2414.77 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute spike count: 100%|███████████████████| 350/350 [00:01<00:00, 197.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID: febb430e-2d50-4f83-87a0-b5ffbb9a4943 # trials: 350 # neurons 465 # time bins 60.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train RRR:: 100%|███████████████████████████| 1000/1000 [05:48<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: -0.061 adj-r2: -2.745\n",
      "pulling data from ibl database ..\n",
      "eid: 88224abb-5746-431f-9c17-17d7ef806e6a\n",
      "pid: 523f8301-4f56-4faf-ab33-a9ff11331118\n",
      "number of trials found: 397\n",
      "found 397 trials from 38.00 to 2184.27 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute spike count: 100%|███████████████████| 397/397 [00:03<00:00, 117.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID: 523f8301-4f56-4faf-ab33-a9ff11331118 # trials: 397 # neurons 505 # time bins 60.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train RRR:: 100%|███████████████████████████| 1000/1000 [06:10<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: -0.009 adj-r2: -0.095\n"
     ]
    }
   ],
   "source": [
    "R = 2\n",
    "behavior_type = \"wheel_speed\"\n",
    "\n",
    "pids = [\n",
    "    # \"dab512bd-a02d-4c1f-8dbc-9155a163efc0\",\n",
    "    \"febb430e-2d50-4f83-87a0-b5ffbb9a4943\",\n",
    "    \"523f8301-4f56-4faf-ab33-a9ff11331118\",\n",
    "    \"84bb830f-b9ff-4e6b-9296-f458fb41d160\",\n",
    "    '0b8ea3ec-e75b-41a1-9442-64f5fbc11a5a',\n",
    "]\n",
    "\n",
    "for pid in pids:\n",
    "    \n",
    "    try:\n",
    "        X_dict, Y_dict = load_data_from_pids(\n",
    "            [pid],\n",
    "            brain_region=\"all\",\n",
    "            behavior=behavior_type,\n",
    "            data_type=\"all_ks\",\n",
    "            n_t_bins = 60,\n",
    "            # align_time_type=\"feedback_times\",\n",
    "            align_time_type=\"firstMovement_times\",\n",
    "            t_before=0.2,\n",
    "            t_after=1.0,\n",
    "            normalize_input=False\n",
    "        )\n",
    "    except:\n",
    "        print(f\"PID {pid} data missing.\")\n",
    "    \n",
    "    X, Y = X_dict[pid], Y_dict[pid]\n",
    "    offset = Y.max()\n",
    "    Y /= offset\n",
    "    K, C, T = X.shape\n",
    "    print(f\"PID: {pid} # trials: {K} # neurons {C} # time bins {T}.\")\n",
    "    \n",
    "    baseline_metrics = []\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=666)\n",
    "    for fold_idx, (train, test) in enumerate(kf.split(X, Y)):\n",
    "        pass\n",
    "        \n",
    "    # baseline\n",
    "    window_X = sliding_window_over_time(X, window_size=10)\n",
    "    window_Y = sliding_window_over_time(Y, window_size=10)\n",
    "    train_X, test_X = window_X[train], window_X[test]\n",
    "    train_Y, test_Y = window_Y[train], window_Y[test]\n",
    "\n",
    "    rrr, losses = train_rrr(\n",
    "        X = X,\n",
    "        Y = Y, \n",
    "        train = train,\n",
    "        test = test,\n",
    "        n_r = R,\n",
    "        learning_rate = 1e-2,\n",
    "        n_epochs = 1000\n",
    "    )\n",
    "\n",
    "    supervised_subspace = rrr.U.detach().numpy()\n",
    "    subspace_weights = rrr.V.detach().numpy()\n",
    "\n",
    "    all_proj = X.transpose(0,-1,1) @ supervised_subspace\n",
    "    weighted_proj = all_proj * subspace_weights.T\n",
    "    weighted_proj = weighted_proj.transpose(0, -1, 1)\n",
    "\n",
    "    window_X = sliding_window_over_time(weighted_proj, window_size=10)\n",
    "    window_Y = sliding_window_over_time(Y, window_size=10)\n",
    "    train_X, test_X = window_X[train], window_X[test]\n",
    "    train_Y, test_Y = window_Y[train], window_Y[test]\n",
    "    rrr_pred, rrr_metric = causal_decoder(train_X, train_Y, test_X, test_Y)\n",
    "\n",
    "    save_path = Path(\"./sensitivity_rank\") / \"wheel_speed\" / f\"rank_{R}\"\n",
    "    os.makedirs(save_path, exist_ok=True) \n",
    "    np.save(save_path/f\"{pid}.npy\", rrr_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0137cbb7-144c-4a2e-9462-9a3a0a566f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906127af-d459-42de-95f2-a222a1dcf4dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
